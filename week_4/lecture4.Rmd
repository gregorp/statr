---
title: 'StatR 502 Lecture 4:\nMore GLMs & Outliers'
author: "Gregor Thomas"
date: "Thursday, January 28, 2016"
output:
  ioslides_presentation:
    fig_height: 3.5
    fig_width: 5
    highlights: pygments
    incremental: yes
    theme: cosmo
  beamer_presentation:
    colortheme: dolphin
    fig_height: 3
    fig_width: 4
    highlight: kate
    incremental: yes
    theme: boadilla
fontsize: 8pt
---

## Announcements:

- For loop forum is up!
- Coming soon: function forum
 
```{r, echo = FALSE, include=FALSE}
packages = c("ggplot2", "arm", "stringr", "MASS", "faraway",
             "magrittr", "reshape2", "tidyr", "gridExtra", "dplyr")
lapply(packages, library, character.only = T)
theme_set(theme_bw(10))
```

## Tonight's Menu:

* Quick review
* All those diagnostic plots we breezed by...
* Non-logistic GLMs
    * Quasi-distributions
* Outliers
    * Identification
    * What to do?

## Quick Review

Things you should know off the top of your head

- AIC: which direction is better?
- What's the difference between AIC and BIC?
- What is the point of linear transformations of data?
- In logistic regression, what does the linear predictor predict?

## Quick Review

Things you should know off the top of your head

- AIC: which direction is better? *Lower is better.*
- What's the difference between AIC and BIC? *BIC penalizes extra parameters based on the size of the data*
- What is the point of linear transformations of data? *make interpretation easier*
- In logistic regression, what does the linear predictor predict? *the log of the odds ratio, log(p / (1-p))*

## A simple regression

The `gala` data in the `faraway` package has the counts of plant species on each of the 70 Galapagos Islands, as well as some numeric characteristics of each island.

```{r}
library(faraway)
str(gala)
gala$Endemics = NULL
```

We'll ignore the `Endemics` column (the count of endemic plant species).

---

We'll start off with OLS. (We'll do this example quickly, if we were taking our time, we'd definitely want to center and scale some of the predictors.)

```{r}
mod = glm(Species ~ ., data = gala, family = gaussian)
# ~ . is shorthand for "all the columns"
display(mod)
```

## How does it look?

Let's look at the residuals:

```{r, fig.height = 4}
plot(mod, 1)
```

---

Same thing with `broom` and `ggplot2`:

```{r}
library(broom)
gala_aug = augment(mod)
g_resid = ggplot(gala_aug, aes(x = .fitted, y = .resid)) +
    geom_point()
```

---

```{r, echo = FALSE}
g_resid
```

This is **heteroskedasticity**---non-uniform variance. The variance of the residuals increases with the response. A log-transform would certainly help, but we have new options...

## Non-logistic GLMs

Last week, we defined a Generalized Linear Model:

$$
g(E(y)) = X\beta  \Rightarrow E(y) = g^{-1} (X \beta )
$$

The function $g$ is called the "link function", and $X\beta$ is called the "linear predictor."

Logistic regression, with the logistic link function and binomial error distribution is by far the most common version of a GLM. 

Other options are Poisson distribution with a log link (typically used for count data), multinomial logistic models, Gamma distribution with several possible links, ...

## When to use what

You can think of GLMs as a broad class of special cases. The logistic GLM is both the most common and (barring perhaps multinomial) the most challenging to interpret. What we did last week with logistic regression (e.g., deviance, methods of transforming back to the original scale) apply to all GLMs.

GLMs are all about getting the *error* right. The normal distribution has the wondefully convenient property that its *location* (mean) and *scale* (standard deviation or variance) are independent. Other distributions have strict relationships between the expected value and the variance:

## A few possible GLM families

- **Binomial** $E(X) = np$, $\mathrm{Var}(X) = np(1 - p)$
- **Poisson** $E(X) = \lambda$, $\mathrm{Var}(X) = \lambda$
- **Gamma** $E(X) = \frac{\alpha}{\beta}$, $\mathrm{Var}(X) = \frac{\alpha}{\beta^2}$
- **Negative Binomial** $E(X) = \frac{pr}{1 - p}$, $\mathrm{Var}(X) = \frac{pr}{(1 - p)^2}$

*NB:* Negative Binomial GLMs are not supported by `stats::glm`, but several other packages have it built in. I use `MASS::glm.nb`

## Back to the Species model

We already know that we could transform the response. Both square-root and log transforms would be good choices for this pattern in the errors.

But, we could also fit a Poisson GLM. Poisson regression is most commonly used for *count data*, that is, counts of things. 


```{r}
modlog = glm(log(Species) ~ ., data = gala, family = gaussian)
modpois = glm(Species ~ ., data = gala, family = poisson)
```

## Get some predictions

```{r}
# This code is from last year, before I knew about broom :(
gala.pred = gala %>%
    dplyr::select(Species) %>%
    mutate(
        gauss.log = exp(predict(modlog, type = "response")),
        poisson = predict(modpois, type = "response")
        ) %>%
    gather(key = model, value = fitted, -Species) %>%
    mutate(resid = Species - fitted,
           log.spec = log(Species))
```

---

Plotting the residuals by response:

```{r, fig.height= 2.5, fig.width=5, echo = FALSE}
ggplot(gala.pred, aes(x = Species, y = resid)) +
    geom_point() +
    facet_wrap(~ model)
```

```{r}
gala.pred %>% group_by(model) %>%
    summarize(sd.resid = sd(resid))
```

## Common GLMs {.smaller}

- Binomial (logistic or probit link) is for *binary* or *proportion* data
- Poisson (log link) can be used for *counts* and *rates*. (You'll do a rate problem on your homework.)
- Negative Binomial (log link, usually) for count data with *even more variance* than the Poisson model would predict
    - Use `MASS::glm.nb`
- Multinomial (logistic) is for *multinomial* data - it's essentially like running several logistic models
    - Use `nnet::multinom` or the `mlogit` package
    - Or use machine learning classification methods instead
- Gamma (log or inverse link) Sometimes the inverse link can be useful for linearizing things. Similar to NB, the variance goes up very quickly compared to the mean.

## Quasi-distributions

*For the math-lovers* (though wihtout going into details), the normal distribution has a wonderful property of independence between its two *sufficient statistics*: the mean and the variance. They're completely unrelated! When we fit an OLS model with normal error, the model is fit first, and then the error term is estimated from the residuals.

This is not the case in general. The binomial distribution with mean $np$ has variance $np(1-p)$. The Poisson has mean = variance = $\lambda$. When we use one of these distributions in a GLM, the mean is tied to the variance. Usually our model isn't such a perfect reflection of real processes that created the data, and we end up observing more variance. This is called **overdispersion**.

## Quasi-distributions

There is a simple fix: estimating the error separately (as is done in OLS). This is done by using the `quasibinomial` or `quasipoisson` distributions, which correct of the overdispersion. It **doesn't change the coefficients**, but it makes their **standard errors more accurate.**

Note that the overdispersion estimate is applied uniformly.

## When to use a quasi-distribution? {.smaller}

Often! Some recommendations say nearly always. The downside is that you are no longer using a true likelihood, instead using a *quasi-likelihood*, which means the AIC is not provided. (Though deviance still is... there's debate on this issue see, e.g., [Dealing with quasi- models in R](http://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf).)

```{r}
modqpois = glm(Species ~ ., data = gala, family = quasipoisson)
all.equal(coef(modpois), coef(modqpois))
se.coef(modpois)
se.coef(modqpois)
```

## Outliers

What do we do about outliers?

```{r}
fortunes::fortune(251)
```

## 6 Options

Ranged here from extreme (1) to unconcerned (6):

1. "Correct" the point---change the value.
2. Exclude the point---treat it as a missing value.
3. Accomodate it---add variables to the model.
4. Accomodate it---change the modeling approach.
5. Work around it, do a sensitivity analysis and make excuses if necessary.
6. Ignore it---do nothing.

(Credit to next quarter's instructor Assaf Oron for the list this is based on.)

---

How much work is involved in these? Are they easy or hard to implement?

1. "Correct" the point---change the value.
2. Exclude the point---treat it as a missing value.
3. Accomodate it---add variables to the model.
4. Accomodate it---change the modeling approach.
5. Work around it, do a sensitivity analysis and make excuses if necessary.
6. Ignore it---do nothing.

What to do is on an outlier-by-outlier basis. What do you think is the most common approach?

## Choosing between the options

Discussion?

- How does amount of data factor in?
- What if the outlier is due to a rare event?
- How does it depend on the model's purpose?
- Credibility: how does your opinion change of an analysis if the author's exclude outliers?

## Identification

How do we detect outliers:

```{r}
fortunes::fortune(113)
```

Plotting data is a good step. My favorite test for outliers (my favorite statistical test in general) is the IOT: Inter-Ocular Trauma test.

## Leverage, Influence and Cook's Distance

The most concerning outliers---and the most noticeable, usually---are in the response, but a point can be an outlier in any dimension.

The diagonals of the **hat matrix**, $H = X(X'X)^{-1}X'$ are called the leverages. They depend *only on X*, but high leverages indicate that the point *could* have a strong effect on the regression.

The leverages for each point are included as the `.hat` values after you use `broom::augmemt()` on a model.

## Cook's D

A data point is *influential* when it has both a high leverage and a big residual.

**Cook's Distance** or **Cook's D** is a nice overall measurement of how much a single observation effects the overall fit. You can calculate Cook's D for every point in a `glm` or `lm` with  `cooks.distance()`. They are included ny `broom::augment` as `.cooksd`.

A rough rule of thumb is to worry about points if their Cook's D value is greater than $4 / n$. A less rough rule of thumb sets the threshold at $4 / (n - k - 1)$.

## Quick example:

Brain vs body weight for land mammals. Any guesses as to outliers?

```{r}
library(MASS)
mammals$species = row.names(mammals)
mammals.lm = lm(brain ~ body + 0, data = mammals)
mammals.fort = fortify(mammals.lm, mammals)
mammal.plot = ggplot(mammals.fort, aes(x = body, y = brain, color = .cooksd)) +
    geom_point() +
    geom_line(aes(y = .fitted), color = "black") +
    geom_text(aes(label = ifelse(.cooksd > 4 / nrow(mammals.fort), species, "")))
```

---

```{r, echo = FALSE}
mammal.plot
```

- If we look at all the points, the elephants are the only ones with enough leverage to be worrisome.

- We can see another clear outlier, but it doesn't have enough leverage to do much to the coefficients.

## What if we restrict the weight?

```{r}
mamm = filter(mammals, body < 200)
mamm.lm = lm(brain ~ body + 0, data = mamm)
mamm.fort = fortify(mamm.lm, mamm)
mamm.plot = ggplot(mamm.fort, aes(x = body, y = brain, color = .cooksd)) +
    geom_point() +
    geom_line(aes(y = .fitted), color = "black") +
    geom_text(aes(label = ifelse(.cooksd > 4 / nrow(mamm.fort), species, "")))
```

---

```{r, echo = FALSE}
mamm.plot
```

- If we limit the weight to < 200 kg, then humans show up.
- Side question---at a glance, do you think this untransformed linear model is appropriate?

## What to do?

- Fixing and excluding points are drastic measures. You need to make a strong case.
    - In my job, we frequently exclude "short-stayers", children in foster care for less than 7 days, because there's a strong belief in the field that these cases are "different". Sometimes we focus on short-stayers only.

- Adding variables---outliers may just be telling you that you're missing an important predictor. If there's a variable that makes sense to add, do so! But you don't want to have a context-less "outlier flag".
    - Predicting Latino populations in U.S. states. Bordering Mexico or formerly being a part of Mexico could make a good predictor.

## What to do? (continued)

- Adjusting regression assumptions... we'll do an example of robust regression in lab. Using a heavier-tailed distribution or quantile regression can make a model fit resist the influence of outliers.

- Sensitivity analysis. The only cost is more work. It's done if you're not quite sure of:

- **Do nothing.**
    - With even moderately sized data, the effect of outliers may be quite small.
